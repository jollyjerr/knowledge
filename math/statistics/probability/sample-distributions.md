# Sample Distributions

If you take many random samples `X1, X2, X3, ..., Xn` and create a histogram,
you end up with a sample distribution.

All variables are assumed to be independent and identically distributed (iid).
Random sample = iid.

```
Estimator:
theta-hat = a random variable

If X is an estimator and E[X] = mue then X is an unbiased estimator.

Estimate:
theta-hat = an observation or number x
```

The expected value of a sample mean is the same as the expected value of the
distribution itself (one random variable) because expected value of the whole
sample is always an unbiased estimator in any distribution.

Unbiased is a trade off with small variance in a sample distribution. Having
both is the goal.

```
V[sample mean] = o^2/n
```
